{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Inputs & outputs\n- **Inputs:** `final_data/pyfunctions_ai_classified.parquet` containing labeled code snippets and model predictions.\n- **Outputs:** false-positive diagnostics (tables, decile plots, and regression LaTeX output) for Supplementary Figure S3."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\nfrom verbosity_fp_analysis import analyze_verbosity_core\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom stargazer.stargazer import Stargazer"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d7a5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 597,
     "status": "error",
     "timestamp": 1760702252008,
     "user": {
      "displayName": "Johannes Wachs",
      "userId": "07923364722446939044"
     },
     "user_tz": -120
    },
    "id": "9b9d7a5b",
    "outputId": "629b589e-3fb7-49c2-dd23-6214c1eed1fb"
   },
   "outputs": [],
   "source": "\ndf=pd.read_parquet(\"./final_data/pyfunctions_ai_classified.parquet\")\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a916b-7818-4504-8eaf-3659e8f378d9",
   "metadata": {},
   "outputs": [],
   "source": "\n# df must have: modified_blocks (str), user_experience (float), true_label ('human'/'ai'), prediction (float; P(ai))\nres = analyze_verbosity_core(\n    df,\n    ai_threshold=0.5,\n    prediction_is_ai_prob=True,\n    individual_features=['avg_line_len','blank_ratio','comment_ratio','docstring_len','n_tokens']\n)\n\n# 1) Correlations table (humans)\ncorr_tbl = res[\"corr_table\"].copy().sort_values(\"variable\").reset_index(drop=True)\ncorr_tbl\n# If you want nicer rounding:\ncorr_tbl_fmt = corr_tbl.assign(\n    spearman_rho=corr_tbl[\"spearman_rho\"].round(3)\n)\ncorr_tbl_fmt\n\n# 2) Decile tables (humans)\ndeciles_vc_tbl = res[\"deciles_VC\"].copy()\ndeciles_vs_tbl = res[\"deciles_VS\"].copy()\n# Optional: add percentage columns\nfor t in (deciles_vc_tbl, deciles_vs_tbl):\n    t[\"fp_rate_pct\"] = (t[\"fp_rate\"]*100).round(1)\ndeciles_vc_tbl, deciles_vs_tbl\n\n# 3) Logistic regression tables\nmodels = res[\"models\"]\n\n# 3a) Coefficients per model (odds ratios included)\ncoef_base = models[\"baseline\"][\"coeffs\"].copy()\ncoef_vs   = models[\"plus_VS\"][\"coeffs\"].copy()\ncoef_full = models[\"full\"][\"coeffs\"].copy()\n\n# add 95% CI for ORs\ndef add_or_ci(df):\n    lo = np.exp(df[\"coef\"] - 1.96*df[\"se\"])\n    hi = np.exp(df[\"coef\"] + 1.96*df[\"se\"])\n    out = df.copy()\n    out[\"OR\"] = df[\"odds_ratio\"].round(3)\n    out[\"OR_lo\"] = lo.round(3)\n    out[\"OR_hi\"] = hi.round(3)\n    return out[[\"term\",\"coef\",\"se\",\"OR\",\"OR_lo\",\"OR_hi\"]]\n\ncoef_base_tbl = add_or_ci(coef_base)\ncoef_vs_tbl   = add_or_ci(coef_vs)\ncoef_full_tbl = add_or_ci(coef_full)\n\n# 3b) Model summary table (AIC/AUC)\nsummary_tbl = pd.DataFrame([\n    {\"model\":\"baseline\", \"AIC\": models[\"baseline\"][\"AIC\"], \"AUC\": models[\"baseline\"][\"AUC\"]},\n    {\"model\":\"+VS\",      \"AIC\": models[\"plus_VS\"][\"AIC\"],  \"AUC\": models[\"plus_VS\"][\"AUC\"]},\n    {\"model\":\"+VS+templated+inter\", \"AIC\": models[\"full\"][\"AIC\"], \"AUC\": models[\"full\"][\"AUC\"]},\n]).assign(AIC=lambda d: d[\"AIC\"].round(2), AUC=lambda d: d[\"AUC\"].round(3))\n\nprint(corr_tbl_fmt)\n\nprint(deciles_vc_tbl)\n\nprint(deciles_vs_tbl)\n\nprint(coef_base_tbl),\nprint(coef_vs_tbl)\nprint(coef_full_tbl)\nprint(summary_tbl)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7a7a4-8ac7-4cca-bccf-90e4d3b1e3a4",
   "metadata": {},
   "outputs": [],
   "source": "# ONE SNIPPET\n# (A) Facet plot of FP deciles for: Composite Verbosity (VS), Composite Verbosity + Size (VC), and Templatedness\n# (B) Combined regression LaTeX table using statsmodels + stargazer (multiple models in one table)\n#\n# Prereqs (once):\n#   pip install matplotlib pandas numpy statsmodels stargazer\n#\n# Assumes you've already run:\n#   from verbosity_fp_analysis import analyze_verbosity_core\n#   res = analyze_verbosity_core(df, ai_threshold=0.5, prediction_is_ai_prob=True)\n\n\n# ===== Pull objects =====\nfeatures  = res[\"features\"].copy()\ndec_vc    = res[\"deciles_VC\"].copy()\ndec_vs    = res[\"deciles_VS\"].copy()\n\n# ===== (A) FACET PLOT: FP rate by decile (VS, VC, Templatedness) =====\nhumans = features[features[\"true_label\"] == \"human\"].copy()\nhumans[\"FP\"] = (humans[\"predicted_label\"] == \"ai\").astype(int)\n\ndef fp_deciles(humans_df, series):\n    q = pd.qcut(series, q=10, labels=False, duplicates=\"drop\")\n    out = humans_df.groupby(q)[\"FP\"].agg([\"mean\",\"count\"]).rename(columns={\"mean\":\"fp_rate\"}).reset_index(names=\"decile\")\n    out[\"fp_rate_pct\"] = out[\"fp_rate\"] * 100.0\n    return out.sort_values(\"decile\").reset_index(drop=True)\n\nfor t in (dec_vc, dec_vs):\n    if \"fp_rate_pct\" not in t.columns:\n        t[\"fp_rate_pct\"] = t[\"fp_rate\"] * 100.0\n\ndec_tmp = fp_deciles(humans, humans[\"templatedness\"])\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 3.8), sharey=True)\n\n# VS\naxes[0].plot(dec_vs[\"decile\"], dec_vs[\"fp_rate_pct\"], marker=\"o\")\naxes[0].axhline(0, linewidth=1)\naxes[0].set_ylim(0, 18)\naxes[0].set_title(\"Composite Verbosity (VS)\")\naxes[0].set_xlabel(\"Decile\")\naxes[0].set_ylabel(\"False positive rate (%)\")\naxes[0].set_xticks(range(10))\naxes[0].set_xticklabels([str(i) for i in range(1, 11)])\n\n# VC\naxes[1].plot(dec_vc[\"decile\"], dec_vc[\"fp_rate_pct\"], marker=\"o\")\naxes[1].axhline(0, linewidth=1)\naxes[1].set_ylim(0, 18)\naxes[1].set_title(\"Composite Verbosity + Size (VC)\")\naxes[1].set_xlabel(\"Decile\")\naxes[1].set_xticks(range(10))\naxes[1].set_xticklabels([str(i) for i in range(1, 11)])\n\n# Templatedness\naxes[2].plot(dec_tmp[\"decile\"], dec_tmp[\"fp_rate_pct\"], marker=\"o\")\naxes[2].axhline(0, linewidth=1)\naxes[2].set_ylim(0, 18)\naxes[2].set_title(\"Templatedness\")\naxes[2].set_xlabel(\"Decile\")\naxes[2].set_xticks(range(10))\naxes[2].set_xticklabels([str(i) for i in range(1, 11)])\n\nfig.tight_layout()\n# fig.savefig(\"fp_rate_deciles_facets.png\", dpi=300)\nplt.show()\n\n# ===== (B) Combined regression LaTeX table with statsmodels + stargazer =====\ndef z(s):\n    s = s.astype(float)\n    return (s - s.mean()) / (s.std(ddof=0) + 1e-12)\n\nhumans[\"z_tokens\"]      = z(humans[\"n_tokens\"])\nhumans[\"z_complexity\"]  = z(humans[\"complexity\"])\nhumans[\"z_experience\"]  = z(humans[\"user_experience\"])\nhumans[\"z_VS\"]          = z(humans[\"verbosity_style_index\"])\nhumans[\"z_templated\"]   = z(humans[\"templatedness\"])\nhumans[\"z_interaction\"] = humans[\"z_VS\"] * humans[\"z_templated\"]\n\ndef fit_logit(y, Xcols, data):\n    X = data[Xcols].copy()\n    X = sm.add_constant(X, has_constant=\"add\")\n    model = sm.Logit(data[y].astype(float), X)\n    return model.fit(disp=0)\n\nm1 = fit_logit(\"FP\", [\"z_tokens\",\"z_complexity\",\"z_experience\"], humans)\nm2 = fit_logit(\"FP\", [\"z_tokens\",\"z_complexity\",\"z_experience\",\"z_VS\"], humans)\nm3 = fit_logit(\"FP\", [\"z_tokens\",\"z_complexity\",\"z_experience\",\"z_VS\",\"z_templated\",\"z_interaction\"], humans)\n\nsg = Stargazer([m1, m2, m3])\nsg.title(\"Logit: False positive (human code)\")\nsg.custom_columns([\"Baseline\", \"+ Composite Verbosity\", \"+ Composite Verbosity, Templatedness, Interaction\"], [1,1,1])\nsg.covariate_order([\n    \"const\",\"z_tokens\",\"z_complexity\",\"z_experience\",\"z_VS\",\"z_templated\",\"z_interaction\"\n])\nsg.rename_covariates({\n    \"const\": \"Intercept\",\n    \"z_tokens\": \"Tokens (z)\",\n    \"z_complexity\": \"Complexity (z)\",\n    \"z_experience\": \"Experience (z)\",\n    \"z_VS\": \"Composite Verbosity (z)\",\n    \"z_templated\": \"Templatedness (z)\",\n    \"z_interaction\": \"Composite Verbosity \u00d7 Templatedness\"\n})\n\nlatex_table = sg.render_latex()\nwith open(\"reg_stargazer.tex\", \"w\", encoding=\"utf-8\") as f:\n    f.write(latex_table)\n\nsg"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32490627-fab6-46e3-ba71-e53c8d69f664",
   "metadata": {},
   "outputs": [],
   "source": "\ndef add_binomial_ci(df, p_col=\"fp_rate\", n_col=\"count\", z=1.96):\n    # df needs columns: p_col in [0,1], n_col = decile counts\n    p = df[p_col].astype(float).values\n    n = df[n_col].astype(float).values\n    se = np.sqrt(np.clip(p*(1-p)/np.maximum(n, 1.0), 0, None))\n    lo = np.clip(p - z*se, 0, 1)\n    hi = np.clip(p + z*se, 0, 1)\n    out = df.copy()\n    out[\"fp_lo\"] = lo\n    out[\"fp_hi\"] = hi\n    out[\"fp_rate_pct\"] = p*100.0\n    out[\"fp_lo_pct\"]   = lo*100.0\n    out[\"fp_hi_pct\"]   = hi*100.0\n    out = out.sort_values(\"decile\").reset_index(drop=True)\n    return out\n\n# If your res[\"deciles_*\"] tables already have \"count\" and \"fp_rate\", this is enough:\ndec_vs_ci = add_binomial_ci(dec_vs)  # needs columns: decile, fp_rate, count\ndec_vc_ci = add_binomial_ci(dec_vc)\n\n# For templatedness we recomputed; it already has count:\ndec_tmp_ci = add_binomial_ci(dec_tmp)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c18cf3",
   "metadata": {},
   "outputs": [],
   "source": "# import os\n# import pandas as pd\n# import matplotlib.pyplot as plt\n# import numpy as np\n\n\n\n# custom_style = {\n#     # Font sizes\n#     \"axes.labelsize\": 25,\n#     \"axes.titlesize\": 20,\n#     \"xtick.labelsize\": 20,\n#     \"ytick.labelsize\": 20,\n\n#     # Line and marker styles\n#     \"lines.linewidth\": 3,\n#     \"lines.markersize\": 8,\n#     \"lines.color\": \"black\",\n#     \"errorbar.capsize\": 5,\n\n#     # Axes & spines\n#     \"axes.edgecolor\": \"black\",\n#     \"axes.linewidth\": 2,\n\n#     # Tick styling\n#     \"xtick.color\": \"black\",\n#     \"ytick.color\": \"black\",\n#     \"xtick.major.width\": 1.2,\n#     \"ytick.major.width\": 1.2,\n\n#     # Grid\n#     \"axes.grid\": True,\n#     \"grid.color\": \"gray\",\n#     \"grid.linewidth\": 0.7,\n#     \"grid.linestyle\": \"--\",\n#     \"grid.alpha\": 0.6,\n\n#     # Figure settings\n#     \"figure.figsize\": (12, 8),\n#     \"figure.dpi\": 300,\n#     \"figure.facecolor\": \"white\"\n# }\n\n\n# plt.rcParams.update(custom_style)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f9a7b",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(12, 3.8), sharey=True)\n\ndef draw(ax, d, title):\n    x = d[\"decile\"].values\n    y = d[\"fp_rate_pct\"].values\n    yerr = np.vstack([y - d[\"fp_lo_pct\"].values, d[\"fp_hi_pct\"].values - y])\n    ax.errorbar(x, y, yerr=yerr, fmt='-o', capsize=3)  # no colors specified\n    ax.axhline(0, linewidth=1)\n    ax.set_ylim(0, 30)\n    ax.set_title(title)\n    ax.set_xlabel(\"Decile\")\n    ax.set_ylabel(\"False positive rate (%)\")\n    ax.set_xticks(range(10))\n    ax.set_xticklabels([str(i) for i in range(1, 11)])\n\ndraw(axes[0], dec_vs_ci, \"Composite Verbosity (VS)\")\ndraw(axes[1], dec_vc_ci, \"Composite Verbosity + Size (VC)\")\ndraw(axes[2], dec_tmp_ci, \"Templatedness\")\n\nfig.tight_layout()\n# plt.savefig(\"/Users/Danio001/Downloads/verbosity.pdf\",dpi=300)\nplt.show()"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "github_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
