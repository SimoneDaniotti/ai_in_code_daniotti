{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d7a5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 597,
     "status": "error",
     "timestamp": 1760702252008,
     "user": {
      "displayName": "Johannes Wachs",
      "userId": "07923364722446939044"
     },
     "user_tz": -120
    },
    "id": "9b9d7a5b",
    "outputId": "629b589e-3fb7-49c2-dd23-6214c1eed1fb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_parquet(\"./final_data/pyfunctions_ai_classified.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a916b-7818-4504-8eaf-3659e8f378d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from verbosity_fp_analysis import analyze_verbosity_core\n",
    "\n",
    "# df must have: modified_blocks (str), user_experience (float), true_label ('human'/'ai'), prediction (float; P(ai))\n",
    "res = analyze_verbosity_core(\n",
    "    df,\n",
    "    ai_threshold=0.5,\n",
    "    prediction_is_ai_prob=True,\n",
    "    individual_features=['avg_line_len','blank_ratio','comment_ratio','docstring_len','n_tokens']\n",
    ")\n",
    "\n",
    "# 1) Correlations table (humans)\n",
    "corr_tbl = res[\"corr_table\"].copy().sort_values(\"variable\").reset_index(drop=True)\n",
    "corr_tbl\n",
    "# If you want nicer rounding:\n",
    "corr_tbl_fmt = corr_tbl.assign(\n",
    "    spearman_rho=corr_tbl[\"spearman_rho\"].round(3)\n",
    ")\n",
    "corr_tbl_fmt\n",
    "\n",
    "# 2) Decile tables (humans)\n",
    "deciles_vc_tbl = res[\"deciles_VC\"].copy()\n",
    "deciles_vs_tbl = res[\"deciles_VS\"].copy()\n",
    "# Optional: add percentage columns\n",
    "for t in (deciles_vc_tbl, deciles_vs_tbl):\n",
    "    t[\"fp_rate_pct\"] = (t[\"fp_rate\"]*100).round(1)\n",
    "deciles_vc_tbl, deciles_vs_tbl\n",
    "\n",
    "# 3) Logistic regression tables\n",
    "models = res[\"models\"]\n",
    "\n",
    "# 3a) Coefficients per model (odds ratios included)\n",
    "coef_base = models[\"baseline\"][\"coeffs\"].copy()\n",
    "coef_vs   = models[\"plus_VS\"][\"coeffs\"].copy()\n",
    "coef_full = models[\"full\"][\"coeffs\"].copy()\n",
    "\n",
    "# add 95% CI for ORs\n",
    "def add_or_ci(df):\n",
    "    lo = np.exp(df[\"coef\"] - 1.96*df[\"se\"])\n",
    "    hi = np.exp(df[\"coef\"] + 1.96*df[\"se\"])\n",
    "    out = df.copy()\n",
    "    out[\"OR\"] = df[\"odds_ratio\"].round(3)\n",
    "    out[\"OR_lo\"] = lo.round(3)\n",
    "    out[\"OR_hi\"] = hi.round(3)\n",
    "    return out[[\"term\",\"coef\",\"se\",\"OR\",\"OR_lo\",\"OR_hi\"]]\n",
    "\n",
    "coef_base_tbl = add_or_ci(coef_base)\n",
    "coef_vs_tbl   = add_or_ci(coef_vs)\n",
    "coef_full_tbl = add_or_ci(coef_full)\n",
    "\n",
    "# 3b) Model summary table (AIC/AUC)\n",
    "summary_tbl = pd.DataFrame([\n",
    "    {\"model\":\"baseline\", \"AIC\": models[\"baseline\"][\"AIC\"], \"AUC\": models[\"baseline\"][\"AUC\"]},\n",
    "    {\"model\":\"+VS\",      \"AIC\": models[\"plus_VS\"][\"AIC\"],  \"AUC\": models[\"plus_VS\"][\"AUC\"]},\n",
    "    {\"model\":\"+VS+templated+inter\", \"AIC\": models[\"full\"][\"AIC\"], \"AUC\": models[\"full\"][\"AUC\"]},\n",
    "]).assign(AIC=lambda d: d[\"AIC\"].round(2), AUC=lambda d: d[\"AUC\"].round(3))\n",
    "\n",
    "print(corr_tbl_fmt)\n",
    "\n",
    "print(deciles_vc_tbl)\n",
    "\n",
    "print(deciles_vs_tbl)\n",
    "\n",
    "print(coef_base_tbl),\n",
    "print(coef_vs_tbl)\n",
    "print(coef_full_tbl)\n",
    "print(summary_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7a7a4-8ac7-4cca-bccf-90e4d3b1e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE SNIPPET\n",
    "# (A) Facet plot of FP deciles for: Composite Verbosity (VS), Composite Verbosity + Size (VC), and Templatedness\n",
    "# (B) Combined regression LaTeX table using statsmodels + stargazer (multiple models in one table)\n",
    "#\n",
    "# Prereqs (once):\n",
    "#   pip install matplotlib pandas numpy statsmodels stargazer\n",
    "#\n",
    "# Assumes you've already run:\n",
    "#   from verbosity_fp_analysis import analyze_verbosity_core\n",
    "#   res = analyze_verbosity_core(df, ai_threshold=0.5, prediction_is_ai_prob=True)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "# ===== Pull objects =====\n",
    "features  = res[\"features\"].copy()\n",
    "dec_vc    = res[\"deciles_VC\"].copy()\n",
    "dec_vs    = res[\"deciles_VS\"].copy()\n",
    "\n",
    "# ===== (A) FACET PLOT: FP rate by decile (VS, VC, Templatedness) =====\n",
    "humans = features[features[\"true_label\"] == \"human\"].copy()\n",
    "humans[\"FP\"] = (humans[\"predicted_label\"] == \"ai\").astype(int)\n",
    "\n",
    "def fp_deciles(humans_df, series):\n",
    "    q = pd.qcut(series, q=10, labels=False, duplicates=\"drop\")\n",
    "    out = humans_df.groupby(q)[\"FP\"].agg([\"mean\",\"count\"]).rename(columns={\"mean\":\"fp_rate\"}).reset_index(names=\"decile\")\n",
    "    out[\"fp_rate_pct\"] = out[\"fp_rate\"] * 100.0\n",
    "    return out.sort_values(\"decile\").reset_index(drop=True)\n",
    "\n",
    "for t in (dec_vc, dec_vs):\n",
    "    if \"fp_rate_pct\" not in t.columns:\n",
    "        t[\"fp_rate_pct\"] = t[\"fp_rate\"] * 100.0\n",
    "\n",
    "dec_tmp = fp_deciles(humans, humans[\"templatedness\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3.8), sharey=True)\n",
    "\n",
    "# VS\n",
    "axes[0].plot(dec_vs[\"decile\"], dec_vs[\"fp_rate_pct\"], marker=\"o\")\n",
    "axes[0].axhline(0, linewidth=1)\n",
    "axes[0].set_ylim(0, 18)\n",
    "axes[0].set_title(\"Composite Verbosity (VS)\")\n",
    "axes[0].set_xlabel(\"Decile\")\n",
    "axes[0].set_ylabel(\"False positive rate (%)\")\n",
    "axes[0].set_xticks(range(10))\n",
    "axes[0].set_xticklabels([str(i) for i in range(1, 11)])\n",
    "\n",
    "# VC\n",
    "axes[1].plot(dec_vc[\"decile\"], dec_vc[\"fp_rate_pct\"], marker=\"o\")\n",
    "axes[1].axhline(0, linewidth=1)\n",
    "axes[1].set_ylim(0, 18)\n",
    "axes[1].set_title(\"Composite Verbosity + Size (VC)\")\n",
    "axes[1].set_xlabel(\"Decile\")\n",
    "axes[1].set_xticks(range(10))\n",
    "axes[1].set_xticklabels([str(i) for i in range(1, 11)])\n",
    "\n",
    "# Templatedness\n",
    "axes[2].plot(dec_tmp[\"decile\"], dec_tmp[\"fp_rate_pct\"], marker=\"o\")\n",
    "axes[2].axhline(0, linewidth=1)\n",
    "axes[2].set_ylim(0, 18)\n",
    "axes[2].set_title(\"Templatedness\")\n",
    "axes[2].set_xlabel(\"Decile\")\n",
    "axes[2].set_xticks(range(10))\n",
    "axes[2].set_xticklabels([str(i) for i in range(1, 11)])\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"fp_rate_deciles_facets.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ===== (B) Combined regression LaTeX table with statsmodels + stargazer =====\n",
    "def z(s):\n",
    "    s = s.astype(float)\n",
    "    return (s - s.mean()) / (s.std(ddof=0) + 1e-12)\n",
    "\n",
    "humans[\"z_tokens\"]      = z(humans[\"n_tokens\"])\n",
    "humans[\"z_complexity\"]  = z(humans[\"complexity\"])\n",
    "humans[\"z_experience\"]  = z(humans[\"user_experience\"])\n",
    "humans[\"z_VS\"]          = z(humans[\"verbosity_style_index\"])\n",
    "humans[\"z_templated\"]   = z(humans[\"templatedness\"])\n",
    "humans[\"z_interaction\"] = humans[\"z_VS\"] * humans[\"z_templated\"]\n",
    "\n",
    "def fit_logit(y, Xcols, data):\n",
    "    X = data[Xcols].copy()\n",
    "    X = sm.add_constant(X, has_constant=\"add\")\n",
    "    model = sm.Logit(data[y].astype(float), X)\n",
    "    return model.fit(disp=0)\n",
    "\n",
    "m1 = fit_logit(\"FP\", [\"z_tokens\",\"z_complexity\",\"z_experience\"], humans)\n",
    "m2 = fit_logit(\"FP\", [\"z_tokens\",\"z_complexity\",\"z_experience\",\"z_VS\"], humans)\n",
    "m3 = fit_logit(\"FP\", [\"z_tokens\",\"z_complexity\",\"z_experience\",\"z_VS\",\"z_templated\",\"z_interaction\"], humans)\n",
    "\n",
    "sg = Stargazer([m1, m2, m3])\n",
    "sg.title(\"Logit: False positive (human code)\")\n",
    "sg.custom_columns([\"Baseline\", \"+ Composite Verbosity\", \"+ Composite Verbosity, Templatedness, Interaction\"], [1,1,1])\n",
    "sg.covariate_order([\n",
    "    \"const\",\"z_tokens\",\"z_complexity\",\"z_experience\",\"z_VS\",\"z_templated\",\"z_interaction\"\n",
    "])\n",
    "sg.rename_covariates({\n",
    "    \"const\": \"Intercept\",\n",
    "    \"z_tokens\": \"Tokens (z)\",\n",
    "    \"z_complexity\": \"Complexity (z)\",\n",
    "    \"z_experience\": \"Experience (z)\",\n",
    "    \"z_VS\": \"Composite Verbosity (z)\",\n",
    "    \"z_templated\": \"Templatedness (z)\",\n",
    "    \"z_interaction\": \"Composite Verbosity Ã— Templatedness\"\n",
    "})\n",
    "\n",
    "latex_table = sg.render_latex()\n",
    "with open(\"reg_stargazer.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32490627-fab6-46e3-ba71-e53c8d69f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_binomial_ci(df, p_col=\"fp_rate\", n_col=\"count\", z=1.96):\n",
    "    # df needs columns: p_col in [0,1], n_col = decile counts\n",
    "    p = df[p_col].astype(float).values\n",
    "    n = df[n_col].astype(float).values\n",
    "    se = np.sqrt(np.clip(p*(1-p)/np.maximum(n, 1.0), 0, None))\n",
    "    lo = np.clip(p - z*se, 0, 1)\n",
    "    hi = np.clip(p + z*se, 0, 1)\n",
    "    out = df.copy()\n",
    "    out[\"fp_lo\"] = lo\n",
    "    out[\"fp_hi\"] = hi\n",
    "    out[\"fp_rate_pct\"] = p*100.0\n",
    "    out[\"fp_lo_pct\"]   = lo*100.0\n",
    "    out[\"fp_hi_pct\"]   = hi*100.0\n",
    "    out = out.sort_values(\"decile\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# If your res[\"deciles_*\"] tables already have \"count\" and \"fp_rate\", this is enough:\n",
    "dec_vs_ci = add_binomial_ci(dec_vs)  # needs columns: decile, fp_rate, count\n",
    "dec_vc_ci = add_binomial_ci(dec_vc)\n",
    "\n",
    "# For templatedness we recomputed; it already has count:\n",
    "dec_tmp_ci = add_binomial_ci(dec_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c18cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# custom_style = {\n",
    "#     # Font sizes\n",
    "#     \"axes.labelsize\": 25,\n",
    "#     \"axes.titlesize\": 20,\n",
    "#     \"xtick.labelsize\": 20,\n",
    "#     \"ytick.labelsize\": 20,\n",
    "\n",
    "#     # Line and marker styles\n",
    "#     \"lines.linewidth\": 3,\n",
    "#     \"lines.markersize\": 8,\n",
    "#     \"lines.color\": \"black\",\n",
    "#     \"errorbar.capsize\": 5,\n",
    "\n",
    "#     # Axes & spines\n",
    "#     \"axes.edgecolor\": \"black\",\n",
    "#     \"axes.linewidth\": 2,\n",
    "\n",
    "#     # Tick styling\n",
    "#     \"xtick.color\": \"black\",\n",
    "#     \"ytick.color\": \"black\",\n",
    "#     \"xtick.major.width\": 1.2,\n",
    "#     \"ytick.major.width\": 1.2,\n",
    "\n",
    "#     # Grid\n",
    "#     \"axes.grid\": True,\n",
    "#     \"grid.color\": \"gray\",\n",
    "#     \"grid.linewidth\": 0.7,\n",
    "#     \"grid.linestyle\": \"--\",\n",
    "#     \"grid.alpha\": 0.6,\n",
    "\n",
    "#     # Figure settings\n",
    "#     \"figure.figsize\": (12, 8),\n",
    "#     \"figure.dpi\": 300,\n",
    "#     \"figure.facecolor\": \"white\"\n",
    "# }\n",
    "\n",
    "\n",
    "# plt.rcParams.update(custom_style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3.8), sharey=True)\n",
    "\n",
    "def draw(ax, d, title):\n",
    "    x = d[\"decile\"].values\n",
    "    y = d[\"fp_rate_pct\"].values\n",
    "    yerr = np.vstack([y - d[\"fp_lo_pct\"].values, d[\"fp_hi_pct\"].values - y])\n",
    "    ax.errorbar(x, y, yerr=yerr, fmt='-o', capsize=3)  # no colors specified\n",
    "    ax.axhline(0, linewidth=1)\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Decile\")\n",
    "    ax.set_ylabel(\"False positive rate (%)\")\n",
    "    ax.set_xticks(range(10))\n",
    "    ax.set_xticklabels([str(i) for i in range(1, 11)])\n",
    "\n",
    "draw(axes[0], dec_vs_ci, \"Composite Verbosity (VS)\")\n",
    "draw(axes[1], dec_vc_ci, \"Composite Verbosity + Size (VC)\")\n",
    "draw(axes[2], dec_tmp_ci, \"Templatedness\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(\"/Users/Danio001/Downloads/verbosity.pdf\",dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a3e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "github_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
