{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Inputs & outputs\n- **Inputs:** O*NET task statement and rating Excel files in `../final_data/s8_salary_data/` plus BLS wage tables.\n- **Outputs:** serialized task vectors, programming-hour weights, and salary reference tables used to build Supplementary Figure S8."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport pickle\nfrom collections import defaultdict\nimport numpy as np\nimport json\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\nimport matplotlib.font_manager"
  },
  {
   "cell_type": "markdown",
   "id": "f4f6ff49-2997-4b65-9a1a-ddf829ec6945",
   "metadata": {},
   "source": "# read data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1ba5a-dbc7-40f5-9b51-b228f1e90d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:43:53.967322Z",
     "iopub.status.busy": "2025-12-15T10:43:53.967032Z",
     "iopub.status.idle": "2025-12-15T10:44:07.505393Z",
     "shell.execute_reply": "2025-12-15T10:44:07.504751Z",
     "shell.execute_reply.started": "2025-12-15T10:43:53.967290Z"
    }
   },
   "outputs": [],
   "source": "#import pickle5 as pickle\ndef save_obj(obj, name, data_path_save = 'obj/'):\n    with open(data_path_save + name + '.pkl', 'wb') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n        \n\ndef load_obj(name, data_path_load = 'obj/'):\n    with open(data_path_load + name + '.pkl', 'rb') as f:\n        return pickle.load(f)\n\n\ndata_path = '../final_data/s8_salary_data/'\ndf_task_statement = pd.read_excel(data_path + 'Task Statements.xlsx')\n\n\n\n## task statements\ntask_content = {}\njob_tasklist = defaultdict(list)\njob_content = {}\njob_tasktype_list = defaultdict(list)\nfor soc_id,soc_job, task_id, task, core_sup in zip(df_task_statement['O*NET-SOC Code'],df_task_statement['Title'], df_task_statement['Task ID'],  df_task_statement['Task'], df_task_statement['Task Type']):\n    task_content[str(task_id)] = task\n    job_tasklist[soc_id].append(str(task_id))\n    job_content[soc_id] = soc_job\n    if pd.isna(core_sup):\n        job_tasktype_list[soc_id].append('Not Available')\n    else:\n        job_tasktype_list[soc_id].append(core_sup)\n\n\n## task rating\ndf_task_rating = pd.read_excel(data_path + 'Task Ratings.xlsx')\n\n\ncategory_dict = {str(i+1):i for i in range(7)}\njob_task_bool = defaultdict(bool)\njob_task_value_ft = {}\njob_task_value_im = defaultdict(float)\njob_task_value_rt = defaultdict(float)\n\nfor soc_id, task_id, scale_id, category, data_value in zip(df_task_rating['O*NET-SOC Code'], df_task_rating['Task ID'], df_task_rating['Scale ID'], df_task_rating['Category'], df_task_rating['Data Value']):\n    if scale_id == 'FT':\n        if not job_task_bool[(soc_id, str(task_id))]:\n            job_task_bool[(soc_id, str(task_id))] = True\n            job_task_value_ft[(soc_id, str(task_id))] = [0 for _ in range(7)]\n\n        job_task_value_ft[(soc_id, str(task_id))][category_dict[str(int(category))]] = data_value\n\n    if scale_id == 'IM':\n        job_task_value_im[(soc_id, str(task_id))] = data_value\n\n    if scale_id == 'RT':\n        job_task_value_rt[(soc_id, str(task_id))] = data_value\n\nprint(len(job_task_value_ft), len(job_task_value_im), len(job_task_value_rt))\n\n\nmissing_pairs = []\njob_ftlist = defaultdict(list)\njob_tasklist_ft = defaultdict(list)\n\nfor soc_id, tasks in job_tasklist.items():\n    for task_id in tasks:\n        if job_task_bool[(soc_id, task_id)]:\n            job_ftlist[soc_id].append(job_task_value_ft[(soc_id, task_id)])\n            job_tasklist_ft[soc_id].append(task_id)\n\n        else:\n            missing_pairs.append([(soc_id, task_id)])\n\n\nsave_obj(job_ftlist,'job_ftvector_list', data_path)\nsave_obj(job_tasklist_ft,'job_tasklist_ft', data_path)\nsave_obj(missing_pairs, 'missing_pairs', data_path)\nsave_obj(job_task_value_rt, 'job_task_value_rt', data_path)\nsave_obj(job_task_value_im, 'job_task_value_im', data_path)\nsave_obj(task_content, 'task_content',data_path)\nsave_obj(job_content, 'job_content',data_path)\nsave_obj(job_tasktype_list, 'job_tasktype_list',data_path)"
  },
  {
   "cell_type": "markdown",
   "id": "7a260a24-bb9d-4089-9636-0a7a64c3e6bb",
   "metadata": {},
   "source": "# LLM prompts"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228a091-b9b5-4b32-9678-2c772c1f38eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:44:07.506017Z",
     "iopub.status.busy": "2025-12-15T10:44:07.505852Z",
     "iopub.status.idle": "2025-12-15T10:44:07.509074Z",
     "shell.execute_reply": "2025-12-15T10:44:07.508670Z",
     "shell.execute_reply.started": "2025-12-15T10:44:07.506004Z"
    }
   },
   "outputs": [],
   "source": "# job_tasklist_ft = load_obj('job_tasklist_ft', data_path)\n# task_content =load_obj('task_content',data_path)\n# job_content = load_obj('job_content',data_path)\n\n# import requests\n# from collections import defaultdict\n\n# job_task_programming_score = {}\n\n# # Ollama API \u5730\u5740\n# api_url = \"\"\n\n# for soc_id, task_list in job_tasklist_ft.items():\n#     print(job_content[soc_id])\n#     job_task_programming_score[soc_id] = {}\n    \n#     for t in task_list:\n#         question = ''''''\n        \n#         payload = {\n#             \"model\": \"llama3.3:latest\",  # \u6a21\u578b\u540d\u79f0\n#             \"prompt\":question,  # \u8f93\u5165\u7684\u63d0\u793a\u6587\u672c\n#             \"stream\": False,  # \u662f\u5426\u6d41\u5f0f\u8f93\u51fa\n#             \"max_tokens\": 20000,  # \u9650\u5236\u751f\u6210\u7684\u6700\u5927\u957f\u5ea6\n#             \"temperature\": 0.1,  # \u63a7\u5236\u751f\u6210\u6587\u672c\u7684\u968f\u673a\u6027\n#             \"top_p\": 0.1,  # \u63a7\u5236\u751f\u6210\u6587\u672c\u7684\u591a\u6837\u6027\n#         }\n        \n#         # \u53d1\u9001 POST \u8bf7\u6c42\n#         response = requests.post(api_url, json=payload)\n        \n#         # \u68c0\u67e5\u54cd\u5e94\u72b6\u6001\n#         if response.status_code == 200:\n#             # \u89e3\u6790\u54cd\u5e94\u5185\u5bb9\n#             result = response.json()\n#             result_temp = result.get(\"response\")\n#             print(\"\u751f\u6210\u7684\u6587\u672c\uff1a\", result_temp)\n#             job_task_programming_score[soc_id][t] = result_temp\n#         else:\n#             print(\"\u8bf7\u6c42\u5931\u8d25\uff0c\u72b6\u6001\u7801\uff1a\", response.status_code)\n#             print(\"\u9519\u8bef\u4fe1\u606f\uff1a\", response.text)\n#             job_task_programming_score[soc_id][t] = 10086\n\n#     break"
  },
  {
   "cell_type": "markdown",
   "id": "60aac5fc-0b57-47a1-a34f-f2b9379ac265",
   "metadata": {},
   "source": "# get working hours"
  },
  {
   "cell_type": "markdown",
   "id": "8aee6af2-0b7a-42af-93fb-400f5a4e5730",
   "metadata": {},
   "source": "## examples"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f6f91-6b7f-4a0e-acbb-7002ecd553a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:44:07.509488Z",
     "iopub.status.busy": "2025-12-15T10:44:07.509384Z",
     "iopub.status.idle": "2025-12-15T10:44:07.578257Z",
     "shell.execute_reply": "2025-12-15T10:44:07.577601Z",
     "shell.execute_reply.started": "2025-12-15T10:44:07.509478Z"
    }
   },
   "outputs": [],
   "source": "job_ftlist = load_obj('job_ftvector_list', data_path)\njob_tasklist_ft = load_obj('job_tasklist_ft', data_path)\n\nhour_vector = [0, 0.02*8, 0.05*8, 0.08*8, 0.10*8, 0.25*8, 0.5*8]\n\nsoc_working_time_vector_per_day = {}\nfor soc_id, ft_matrix in job_ftlist.items():\n    ftm = np.array(ft_matrix)\n    ftm_normalized = ftm / (np.sum(ftm, axis = 0) + 0.0000000001)\n    soc_working_time_vector_per_day[soc_id] = ftm_normalized.dot(np.array(hour_vector).T) / 8\n\nsave_obj(soc_working_time_vector_per_day, 'soc_working_time_vector_example_1_ft_normalized', data_path)\n\n\njob_ftlist = load_obj('job_ftvector_list', data_path)\njob_tasklist_ft = load_obj('job_tasklist_ft', data_path)\n\nhour_vector = [0.5, 1, 4, 48, 240, 480, 1920]\n\nsoc_working_time_vector = {}\nfor soc_id, ft_matrix in job_ftlist.items():\n    temp = np.array(ft_matrix).dot(np.array(hour_vector).T)\n    soc_working_time_vector[soc_id] = temp / np.sum(temp)\n\n\nsave_obj(soc_working_time_vector, 'soc_working_time_vector_example_2_hour_vector', data_path)\n\n\njob_im_dict = load_obj('job_task_value_im', data_path)\njob_tasklist = load_obj('job_tasklist_ft', data_path)\n\njob_im_weighted_time = {}\njob_imrank_weighted_time = {}\n\nfor soc_id, tasklist in job_tasklist.items():\n    im_temp = np.array([job_im_dict[(soc_id, t)] for t in tasklist])\n    arr = -im_temp\n    temp = arr.argsort()\n    ranks = np.empty_like(temp)\n    ranks[temp] = np.arange(len(arr)) + 1\n    rank_weight = 2 * len(tasklist) - ranks\n\n    job_im_weighted_time[soc_id] = im_temp / np.sum(im_temp)\n    job_imrank_weighted_time[soc_id] = rank_weight / np.sum(rank_weight)\n\nsave_obj(job_im_weighted_time, 'job_im_weighted_time', data_path)\nsave_obj(job_imrank_weighted_time, 'job_imrank_weighted_time', data_path)"
  },
  {
   "cell_type": "markdown",
   "id": "a08f8f63-d63c-490f-9e42-bca99fcb8e78",
   "metadata": {},
   "source": "## BLS hours"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf87a63-8e33-44e4-b0d3-f7eb2c065a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:44:49.626099Z",
     "iopub.status.busy": "2025-12-15T10:44:49.625381Z",
     "iopub.status.idle": "2025-12-15T10:44:49.954397Z",
     "shell.execute_reply": "2025-12-15T10:44:49.953745Z",
     "shell.execute_reply.started": "2025-12-15T10:44:49.626070Z"
    }
   },
   "outputs": [],
   "source": "\ndf_job_salary = pd.read_excel(data_path + 'national_M2024_dl_pure_data.xlsx')\ndf_job_salary = df_job_salary[df_job_salary['O_GROUP'] == 'detailed']\n\nannual_salary_bls = {}\nhour_salary_bls = {}\n\nemployment_count_bls = {}\n\nfor soc_id, h, a, emp in zip(df_job_salary['OCC_CODE'], df_job_salary['H_MEAN'], df_job_salary['A_MEAN'], df_job_salary['TOT_EMP']):\n\n    employment_count_bls[soc_id] = emp\n\n    if a != '*':\n        annual_salary_bls[soc_id] = a\n\n    if h != '*':\n        hour_salary_bls[soc_id] = h\n        \nhour_salary_bls_adjust = {}\nhour_salary_bls_adjust.update(hour_salary_bls)\nfor soc_id, a in annual_salary_bls.items():\n    if soc_id not in hour_salary_bls:\n        hour_salary_bls_adjust[soc_id] = a / 2080\n\nannual_salary_bls_adjust = {}\nannual_salary_bls_adjust.update(annual_salary_bls)\nfor soc_id, h in hour_salary_bls.items():\n    if soc_id not in annual_salary_bls:\n        annual_salary_bls_adjust[soc_id] = h * 2080\n\nfor soc_id, h in hour_salary_bls_adjust.items():\n    if abs(h*2080-annual_salary_bls_adjust[soc_id])>20:\n        print(soc_id)\n\nsave_obj(annual_salary_bls,'annual_salary_bls', data_path)\nsave_obj(hour_salary_bls,'hour_salary_bls', data_path)\n\n\n\njob_task_programming_score = load_obj(\"job_task_programming_score_gemini_0_5_adjusted\", data_path)\nps_temp = [ts for j,tsl in job_task_programming_score.items() for t, ts in tsl.items()]\nprint(Counter(ps_temp))\n\nps_dict = {'0':0, '1':0.0055, '2':0.18, '3':0.38, '4':0.63, '5':0.88}\n\ndef calculate_programming_score(soc_working_time_vector):\n\n    job_programming_score_vector = {}\n    job_programming_hour = {}\n\n    for soc_id, tasklist in job_tasklist_ft.items():\n        job_programming_score_vector[soc_id] = np.array([ps_dict[job_task_programming_score[soc_id][t]] for t in tasklist])\n        job_programming_hour[soc_id] = soc_working_time_vector[soc_id].dot(job_programming_score_vector[soc_id])\n\n\n    job_programming_hour_6digit_temp = defaultdict(list)\n    for soc_id, h in job_programming_hour.items():\n        job_programming_hour_6digit_temp[soc_id[:7]].append(h)\n\n    job_programming_hour_6digit = {}\n    for soc_id, hs in job_programming_hour_6digit_temp.items():\n        job_programming_hour_6digit[soc_id] = np.mean(hs)\n\n\n    job_programming_hour_6digit['13-1020'] = (job_programming_hour_6digit['13-1023'] + job_programming_hour_6digit['13-1021'] + job_programming_hour_6digit['13-1022'])/3\n    del job_programming_hour_6digit['13-1023']\n    del job_programming_hour_6digit['13-1021']\n    del job_programming_hour_6digit['13-1022']\n\n    job_programming_hour_6digit['13-2020'] = job_programming_hour_6digit['13-2023']\n    del job_programming_hour_6digit['13-2023']\n\n    job_programming_hour_6digit['29-2010'] = (job_programming_hour_6digit['29-2011'] + job_programming_hour_6digit['29-2012'])/2\n    del job_programming_hour_6digit['29-2011']\n    del job_programming_hour_6digit['29-2012']\n\n\n    job_programming_hour_6digit['31-1120'] = (job_programming_hour_6digit['31-1121'] + job_programming_hour_6digit['31-1122'])/2\n    del job_programming_hour_6digit['31-1121']\n    del job_programming_hour_6digit['31-1122']\n\n    job_programming_hour_6digit['39-7010'] = (job_programming_hour_6digit['39-7011'] + job_programming_hour_6digit['39-7012'])/2\n    del job_programming_hour_6digit['39-7011']\n    del job_programming_hour_6digit['39-7012']\n\n    job_programming_hour_6digit['47-4090'] = (job_programming_hour_6digit['47-4091'] + job_programming_hour_6digit['47-4099'])/2\n    del job_programming_hour_6digit['47-4091']\n    del job_programming_hour_6digit['47-4099']\n\n    job_programming_hour_6digit['51-2020'] = (job_programming_hour_6digit['51-2021'] + job_programming_hour_6digit['51-2022'] + job_programming_hour_6digit['51-2023'])/3\n    del job_programming_hour_6digit['51-2021']\n    del job_programming_hour_6digit['51-2022']\n    del job_programming_hour_6digit['51-2023']\n    \n    job_programming_hour_6digit['51-2090'] = job_programming_hour_6digit['51-2092']\n    del job_programming_hour_6digit['51-2092']\n\n    return job_programming_hour_6digit\n\n\nsoc_working_time_vector = load_obj('soc_working_time_vector_example_1_ft_normalized', data_path)\njob_programming_hour_6digit = calculate_programming_score(soc_working_time_vector)\nsave_obj(job_programming_hour_6digit, 'job_programming_hour_6digit_BLS_example1', data_path)\n\nsoc_working_time_vector = load_obj('soc_working_time_vector_example_2_hour_vector', data_path)\njob_programming_hour_6digit = calculate_programming_score(soc_working_time_vector)\nsave_obj(job_programming_hour_6digit, 'job_programming_hour_6digit_BLS_example2', data_path)\n\nsoc_working_time_vector = load_obj('job_im_weighted_time', data_path)\njob_programming_hour_6digit = calculate_programming_score(soc_working_time_vector)\nsave_obj(job_programming_hour_6digit, 'job_programming_hour_6digit_BLS_im', data_path)\n\nsoc_working_time_vector = load_obj('job_imrank_weighted_time', data_path)\njob_programming_hour_6digit = calculate_programming_score(soc_working_time_vector)\nsave_obj(job_programming_hour_6digit, 'job_programming_hour_6digit_BLS_imrank', data_path)\n\n\nemployment_count_bls['51-2020'] = 273300\nhour_salary_bls_adjust['51-2020'] = 22.15\nannual_salary_bls_adjust['51-2020'] = 46070\n\nsave_obj(annual_salary_bls_adjust,'annual_salary_bls_adjust', data_path)\nsave_obj(hour_salary_bls_adjust,'hour_salary_bls_adjust', data_path)\nsave_obj(employment_count_bls,'employment_count_bls_adjust', data_path)"
  },
  {
   "cell_type": "markdown",
   "id": "c0e59a02-cb7c-48ea-b6ce-10657dd2ea28",
   "metadata": {},
   "source": "# Figure S8 - comparison"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c7cb2-46c5-4dd3-a5e5-081f56b3474c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:49:32.974523Z",
     "iopub.status.busy": "2025-12-15T10:49:32.974172Z",
     "iopub.status.idle": "2025-12-15T10:50:07.931571Z",
     "shell.execute_reply": "2025-12-15T10:50:07.931162Z",
     "shell.execute_reply.started": "2025-12-15T10:49:32.974495Z"
    }
   },
   "outputs": [],
   "source": "task_content = load_obj('task_content',data_path)\njob_content = load_obj('job_content',data_path)\njob_task_programming_score2 = load_obj(\"job_task_programming_score_gemini_0_5_adjusted\", data_path)\njob_task_programming_score1 = load_obj(\"job_task_programming_score_gemini_0_5\", data_path)\njob_task_programming_score3 = load_obj('job_task_programming_score_0_100_from_gemini', data_path)\n\nps_dict1 = {'1':0, '2':0.125, '3':0.375, '4':0.625, '5':0.875}\nps_dict2 = {'0':0, '1':0.055, '2':0.18, '3':0.38, '4':0.63, '5':0.88}\nps_dict3 = {str(v):int(v)/100 for vv in job_task_programming_score3.values() for v in vv.values()}\n\njob_content_list = []\ntask_content_list = []\nscore1 = []\npercent1 = []\nscore2 = []\npercent2 = []\nscore3 = []\npercent3 = []\nfor job, ps in job_task_programming_score1.items():\n    for t, s in ps.items():\n        if job in job_content and t in task_content:\n            job_content_list.append(job_content[job])\n            task_content_list.append(task_content[t])\n            score1.append(job_task_programming_score1[job][t])\n            percent1.append(ps_dict1[job_task_programming_score1[job][t]])\n            score2.append(job_task_programming_score2[job][t])\n            percent2.append(ps_dict2[job_task_programming_score2[job][t]])\n            score3.append(job_task_programming_score3[job][t])\n            percent3.append(ps_dict3[job_task_programming_score3[job][t]])\n\ndf = pd.DataFrame.from_dict({'job':job_content_list, 'task':task_content_list, 'score1':score1, 'percent1':percent1, 'score2':score2, 'percent2':percent2, 'score3':score3, 'percent3':percent3 })\ndf.to_csv(data_path + 'task_score_percent.csv')\n\njob_ftlist = load_obj('job_ftvector_list', data_path)\njob_tasklist_ft = load_obj('job_tasklist_ft', data_path)\n\njob_task_programming_score1 = load_obj(\"job_task_programming_score_gemini_0_5\", data_path)\nps_dict1 = {'1':0, '2':0.125, '3':0.375, '4':0.625, '5':0.875}\n\n\njob_task_programming_score2 = load_obj(\"job_task_programming_score_gemini_0_5_adjusted\", data_path)\nps_dict2 = {'0':0, '1':0.055, '2':0.18, '3':0.38, '4':0.63, '5':0.88}\n\n\njob_task_programming_score3 = load_obj('job_task_programming_score_0_100_from_gemini', data_path)\nps_dict3 = {str(v):int(v)/100 for vv in job_task_programming_score3.values() for v in vv.values()}\n\n\ndf_skills = pd.read_excel(data_path + 'db_29_3_excel/Skills.xlsx')\ndf_abilities = pd.read_excel(data_path + 'db_29_3_excel/Abilities.xlsx')\ndf_knowledges = pd.read_excel(data_path + 'db_29_3_excel/Knowledge.xlsx')\n\ntasks_std = list(set(df_skills['Element ID'])) + list(set(df_abilities['Element ID'])) + list(set(df_knowledges['Element ID']))\ntasks_dict_std  = {s:i for i,s in enumerate(tasks_std)}\n\njob_list = list(set(df_skills['O*NET-SOC Code']))\njob_task_im_vector = {j:np.zeros(len(tasks_std)) for j in job_list}\njob_task_lv_vector = {j:np.zeros(len(tasks_std)) for j in job_list}\n\nfor o, s, imlv, v in zip(df_skills['O*NET-SOC Code'], df_skills['Element ID'], df_skills['Scale ID'], df_skills['Data Value']):\n    if imlv == 'IM':\n        job_task_im_vector[o][tasks_dict_std[s]] = v\n\n    if imlv == 'LV':\n        job_task_lv_vector[o][tasks_dict_std[s]] = v\n\n\nfor o, s, imlv, v in zip(df_abilities['O*NET-SOC Code'], df_abilities['Element ID'], df_abilities['Scale ID'], df_abilities['Data Value']):\n    if imlv == 'IM':\n        job_task_im_vector[o][tasks_dict_std[s]] = v\n\n    if imlv == 'LV':\n        job_task_lv_vector[o][tasks_dict_std[s]] = v\n\n\nfor o, s, imlv, v in zip(df_knowledges['O*NET-SOC Code'], df_knowledges['Element ID'], df_knowledges['Scale ID'], df_knowledges['Data Value']):\n    if imlv == 'IM':\n        job_task_im_vector[o][tasks_dict_std[s]] = v\n\n    if imlv == 'LV':\n        job_task_lv_vector[o][tasks_dict_std[s]] = v\n\nprogramming_id = '2.B.3.e'\n\njob_task_ps_im = {j: v[tasks_dict_std[programming_id]] / np.sum(v) for j,v in job_task_im_vector.items()}\njob_task_ps_lv = {j: v[tasks_dict_std[programming_id]] / np.sum(v) for j,v in job_task_lv_vector.items()}\n\ndf_skills = pd.read_excel(data_path + 'db_29_3_excel/Skills.xlsx')\ndf_abilities = pd.read_excel(data_path + 'db_29_3_excel/Abilities.xlsx')\ndf_knowledges = pd.read_excel(data_path + 'db_29_3_excel/Knowledge.xlsx')\n\ntasks_std = list(set(df_skills['Element ID'])) + list(set(df_abilities['Element ID'])) + list(set(df_knowledges['Element ID']))\ntasks_dict_std  = {s:i for i,s in enumerate(tasks_std)}\n\njob_list = list(set(df_skills['O*NET-SOC Code']))\njob_task_im_vector = {j:np.zeros(len(tasks_std)) for j in job_list}\njob_task_lv_vector = {j:np.zeros(len(tasks_std)) for j in job_list}\n\nfor o, s, imlv, v in zip(df_skills['O*NET-SOC Code'], df_skills['Element ID'], df_skills['Scale ID'], df_skills['Data Value']):\n    if imlv == 'IM':\n        job_task_im_vector[o][tasks_dict_std[s]] = v\n\n    if imlv == 'LV':\n        job_task_lv_vector[o][tasks_dict_std[s]] = v\n\n\nfor o, s, imlv, v in zip(df_abilities['O*NET-SOC Code'], df_abilities['Element ID'], df_abilities['Scale ID'], df_abilities['Data Value']):\n    if imlv == 'IM':\n        job_task_im_vector[o][tasks_dict_std[s]] = v\n\n    if imlv == 'LV':\n        job_task_lv_vector[o][tasks_dict_std[s]] = v\n\n\nfor o, s, imlv, v in zip(df_knowledges['O*NET-SOC Code'], df_knowledges['Element ID'], df_knowledges['Scale ID'], df_knowledges['Data Value']):\n    if imlv == 'IM':\n        job_task_im_vector[o][tasks_dict_std[s]] = v\n\n    if imlv == 'LV':\n        job_task_lv_vector[o][tasks_dict_std[s]] = v\n\nprogramming_id = '2.B.3.e'\n\njob_task_ps_im = {j: v[tasks_dict_std[programming_id]] / np.sum(v) for j,v in job_task_im_vector.items()}\njob_task_ps_lv = {j: v[tasks_dict_std[programming_id]] / np.sum(v) for j,v in job_task_lv_vector.items()}\n\n\n\nsoc_working_time_vector = load_obj('soc_working_time_vector_example_1_ft_normalized', data_path)\n\njob_programming_hour1 = {}\nfor soc_id, tasklist in job_tasklist_ft.items():\n    job_programming_hour1[soc_id] = soc_working_time_vector[soc_id].dot(np.array([ps_dict1[job_task_programming_score1[soc_id][t]] for t in tasklist]))\n\njob_programming_hour2 = {}\nfor soc_id, tasklist in job_tasklist_ft.items():\n    job_programming_hour2[soc_id] = soc_working_time_vector[soc_id].dot(np.array([ps_dict2[job_task_programming_score2[soc_id][t]] for t in tasklist]))\n\njob_programming_hour3 = {}\nfor soc_id, tasklist in job_tasklist_ft.items():\n    job_programming_hour3[soc_id] = soc_working_time_vector[soc_id].dot(np.array([ps_dict3[job_task_programming_score3[soc_id][t]] for t in tasklist]))\n\ncommon_jobs = list(set(job_task_ps_im.keys()).intersection(job_programming_hour1.keys()))\n\ny_ex1 = [job_task_ps_im[j] for j in common_jobs]\nx1_ex1 = [job_programming_hour1[j] for j in common_jobs]\nx2_ex1 = [job_programming_hour2[j] for j in common_jobs]\nx3_ex1 = [job_programming_hour3[j] for j in common_jobs]\n\n\n\nsoc_working_time_vector = load_obj('soc_working_time_vector_example_2_hour_vector', data_path)\n\njob_programming_hour1 = {}\nfor soc_id, tasklist in job_tasklist_ft.items():\n    job_programming_hour1[soc_id] = soc_working_time_vector[soc_id].dot(np.array([ps_dict1[job_task_programming_score1[soc_id][t]] for t in tasklist]))\n\njob_programming_hour2 = {}\nfor soc_id, tasklist in job_tasklist_ft.items():\n    job_programming_hour2[soc_id] = soc_working_time_vector[soc_id].dot(np.array([ps_dict2[job_task_programming_score2[soc_id][t]] for t in tasklist]))\n\njob_programming_hour3 = {}\nfor soc_id, tasklist in job_tasklist_ft.items():\n    job_programming_hour3[soc_id] = soc_working_time_vector[soc_id].dot(np.array([ps_dict3[job_task_programming_score3[soc_id][t]] for t in tasklist]))\n\ncommon_jobs = list(set(job_task_ps_im.keys()).intersection(job_programming_hour1.keys()))\n\ny_ex2 = [job_task_ps_im[j] for j in common_jobs]\nx1_ex2 = [job_programming_hour1[j] for j in common_jobs]\nx2_ex2 = [job_programming_hour2[j] for j in common_jobs]\nx3_ex2 = [job_programming_hour3[j] for j in common_jobs]\n\n\n\n# \u8bbe\u7f6e seaborn \u7684\u4e3b\u9898\n#sns.set_theme(style=\"whitegrid\")\n\nxl = [x1_ex1,x2_ex1,x3_ex1,x1_ex2,x2_ex2,x3_ex2]\nyl = [y_ex1, y_ex1, y_ex1, y_ex2, y_ex2, y_ex2]\nx_labels = [\"programming share (prompt 1)\",\"programming share (prompt 2)\",\"programming share (prompt 3)\",\"programming share (prompt 1)\",\"programming share (prompt 2)\",\"programming share (prompt 3)\"]\n\nccc = 0\nfor x,y,l in zip(xl, yl, x_labels):\n    ccc += 1\n\n    # 1. \u8ba1\u7b97\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u548c p-value\n    corr_coefficient, p_value = pearsonr(x, y)\n\n    # 2. \u7ed8\u5236\u6563\u70b9\u56fe\n    plt.figure(figsize=(8, 6))\n\n    font_dirs = [f'{data_path}helvetica-255/', ]\n    font_files = matplotlib.font_manager.findSystemFonts(fontpaths=font_dirs)\n    for ff in font_files:\n        matplotlib.font_manager.fontManager.addfont(ff)\n\n    plt.rcParams['font.family'] = ['Helvetica']\n    font1 = {'family':'helvetica',\n            'weight' : 'normal',\n            'size'   : 23,\n    }\n\n    scatter_plot = sns.scatterplot(x=x, y=y, s=70) # s\u662f\u70b9\u7684\u5927\u5c0f\n\n    text_str = f'correlation: {corr_coefficient:.2f}'\n    plt.text(0.05, 0.95, text_str, transform=plt.gca().transAxes,\n            fontdict=font1, verticalalignment='top',)\n\n    # \u6dfb\u52a0\u6807\u9898\u548c\u6807\u7b7e\n\n    plt.xlabel(l, fontdict=font1, fontsize = 27)\n    plt.ylabel(\"'programming' importance\", fontdict=font1, fontsize = 27)\n    plt.tick_params(labelsize=12)\n    #plt.legend()\n    plt.rcParams['font.weight'] = 'bold'\n    plt.rcParams['axes.labelweight'] = 'bold'\n    ax=plt.gca();#\u83b7\u5f97\u5750\u6807\u8f74\u7684\u53e5\u67c4\n    ax.spines['bottom'].set_linewidth(2);###\u8bbe\u7f6e\u5e95\u90e8\u5750\u6807\u8f74\u7684\u7c97\u7ec6\n    ax.spines['left'].set_linewidth(2);####\u8bbe\u7f6e\u5de6\u8fb9\u5750\u6807\u8f74\u7684\u7c97\u7ec6\n    ax.spines['right'].set_linewidth(2);###\u8bbe\u7f6e\u53f3\u8fb9\u5750\u6807\u8f74\u7684\u7c97\u7ec6\n    ax.spines['top'].set_linewidth(2);####\u8bbe\u7f6e\u4e0a\u90e8\u5750\u6807\u8f74\u7684\u7c97\u7ec6\n    # \u663e\u793a\u56fe\u50cf\n    plt.xticks([i*0.1 for i in range(9)],[round(i*0.1,1) for i in range(9)])\n    plt.yticks([i*0.004 for i in range(5)],[i*0.004 for i in range(5)])"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
