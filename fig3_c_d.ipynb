{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b752de",
   "metadata": {},
   "source": [
    "# Panel Regressions: AI Use and Developer Productivity\n",
    "\n",
    "This notebook estimates fixed-effects panel regressions examining the relationship between AI code assistant usage and developer productivity metrics.\n",
    "\n",
    "**Input:** `outputs/panel_uq.parquet` (user-quarter panel from `process_data.py`)\n",
    "\n",
    "**Outputs:** \n",
    "- `outputs/main_regressions.pdf` - Main regression coefficient plot\n",
    "- `outputs/interaction_regressions.pdf` - Experience interaction plot  \n",
    "- `outputs/placebo_regressions.pdf` - Pre-period placebo plot\n",
    "- `outputs/ma_extrapolation.pdf` - Measurement error extrapolation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04458489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyfixest as pf\n",
    "from marginaleffects import slopes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot styling\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"axes.titlesize\": 20,\n",
    "    \"xtick.labelsize\": 15,\n",
    "    \"ytick.labelsize\": 15,\n",
    "    \"lines.linewidth\": 3,\n",
    "    \"lines.markersize\": 8,\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.linewidth\": 2,\n",
    "    \"axes.grid\": False,\n",
    "    \"figure.figsize\": (12, 8),\n",
    "    \"figure.dpi\": 300,\n",
    "    \"figure.facecolor\": \"white\"\n",
    "})\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"outputs/panel_uq.parquet\"\n",
    "OUTDIR = \"outputs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# MA windows for robustness checks\n",
    "MA_WINDOWS = [4, 8, 16, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load panel data\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "df = df.sort_values(['IDu', 'q']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Panel dimensions: {len(df)} observations, {df['IDu'].nunique()} users\")\n",
    "print(f\"Quarter range: {df['q'].min()} to {df['q'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep-vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived variables for regressions\n",
    "\n",
    "# Bin experience (median split)\n",
    "df['binned_experience'] = pd.qcut(\n",
    "    df['experience'], 2, labels=False, duplicates='drop'\n",
    ")\n",
    "\n",
    "# Bin lagged AI exposure (quintiles)\n",
    "df['binned_L_AIavF'] = pd.qcut(\n",
    "    df['L_AIavF'], 5, labels=False, duplicates='drop'\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "ma32_subset = df[~df['L_AIma32_iF'].isna()].copy()\n",
    "df_placebo = df[df['q'] < 20221].copy()  # Pre-ChatGPT period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ci(model, term):\n",
    "    \"\"\"Extract estimate and 95% CI from model tidy output.\"\"\"\n",
    "    t = model.tidy()\n",
    "    return (\n",
    "        float(t.loc[term, \"Estimate\"]),\n",
    "        float(t.loc[term, \"2.5%\"]),\n",
    "        float(t.loc[term, \"97.5%\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def run_main_models(data, regressor=\"L_AIavF\"):\n",
    "    \"\"\"Run main regression specifications across all outcome variables.\"\"\"\n",
    "    dvs = [\n",
    "        \"log_Cuq\", \"log_Cuq_mfiles\", \"log_Cuq_wimprt\",\n",
    "        \"log_libQC_all\", \"log_libkQC_all\", \"log_libLQ_all\", \"log_libE_all\",\n",
    "        \"log_libQC_new_u\", \"log_libkQC_new_u\", \"log_libLQ_new_u\", \"log_libE_new_u\"\n",
    "    ]\n",
    "    models = []\n",
    "    for dv in dvs:\n",
    "        m = pf.feols(\n",
    "            f\"{dv} ~ {regressor} | IDu + q\",\n",
    "            data=data,\n",
    "            vcov={'CRV1': 'IDu'}\n",
    "        )\n",
    "        models.append(m)\n",
    "    return models, dvs\n",
    "\n",
    "\n",
    "def run_interaction_models(data):\n",
    "    \"\"\"Run models with experience interaction.\"\"\"\n",
    "    dvs = [\n",
    "        \"log_Cuq\", \"log_Cuq_mfiles\", \"log_Cuq_wimprt\",\n",
    "        \"log_libQC_all\", \"log_libkQC_all\", \"log_libLQ_all\", \"log_libE_all\",\n",
    "        \"log_libQC_new_u\", \"log_libkQC_new_u\", \"log_libLQ_new_u\", \"log_libE_new_u\"\n",
    "    ]\n",
    "    models = []\n",
    "    for dv in dvs:\n",
    "        m = pf.feols(\n",
    "            f\"{dv} ~ binned_experience + L_AIavF + binned_experience*L_AIavF | IDu + q\",\n",
    "            data=data,\n",
    "            vcov={'CRV1': 'IDu'}\n",
    "        )\n",
    "        models.append(m)\n",
    "    return models, dvs\n",
    "\n",
    "\n",
    "def plot_coefficients(models, regressor, filename, title=None):\n",
    "    \"\"\"Create coefficient plot with grouped outcomes.\"\"\"\n",
    "    # Extract estimates\n",
    "    ests, los, his = [], [], []\n",
    "    for m in models:\n",
    "        est, lo, hi = extract_ci(m, regressor)\n",
    "        ests.append(est)\n",
    "        los.append(lo)\n",
    "        his.append(hi)\n",
    "    \n",
    "    ests = np.array(ests)\n",
    "    yerr = np.vstack([ests - np.array(los), np.array(his) - ests])\n",
    "    \n",
    "    # Labels\n",
    "    labels = [\n",
    "        'All', 'Multi-file', 'Imports',\n",
    "        'Combos', 'Combos\\n(Top 5k)', 'Combos\\n(Groups)', 'Indiv.\\nLibs.',\n",
    "        'Combos', 'Combos\\n(Top 5k)', 'Combos\\n(Groups)', 'Indiv.\\nLibs.'\n",
    "    ]\n",
    "    \n",
    "    # Group spacing\n",
    "    group_sizes = [3, 4, 4]\n",
    "    gap = 0.8\n",
    "    x_spaced = []\n",
    "    offset = 0.0\n",
    "    for gsize in group_sizes:\n",
    "        x_spaced.extend(offset + np.arange(gsize))\n",
    "        offset += gsize + gap\n",
    "    x_spaced = np.array(x_spaced)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12.0, 5.0), dpi=300)\n",
    "    ax.errorbar(x_spaced, ests, yerr=yerr, fmt=\"o\", capsize=3, color='black')\n",
    "    ax.axhline(0, lw=1, color=\"black\")\n",
    "    ax.set_xticks(x_spaced)\n",
    "    ax.set_xticklabels(labels, rotation=0, ha=\"center\", fontsize=13)\n",
    "    ax.set_xlim(x_spaced[0] - 0.6, x_spaced[-1] + 0.6)\n",
    "    ax.set_ylabel(\"Estimated marginal\\neffect of AI use\")\n",
    "    ax.tick_params(axis=\"y\", labelsize=13)\n",
    "    \n",
    "    # Group labels\n",
    "    sec = ax.secondary_xaxis(location=-0.17)\n",
    "    sec.spines['bottom'].set_visible(False)\n",
    "    g1_center = x_spaced[0:3].mean()\n",
    "    g2_center = x_spaced[3:7].mean()\n",
    "    g3_center = x_spaced[7:11].mean()\n",
    "    sec.set_xticks(\n",
    "        [g1_center, g2_center, g3_center],\n",
    "        labels=['Commits\\n(log)', 'Library Use\\n(log)', 'Library Entry\\n(log)'],\n",
    "        size=20\n",
    "    )\n",
    "    sec.tick_params('x', length=0)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'{OUTDIR}/{filename}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main-results",
   "metadata": {},
   "source": [
    "## Main Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-regs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run main regressions\n",
    "models, dvs = run_main_models(df)\n",
    "\n",
    "# Display regression table\n",
    "pf.etable(\n",
    "    models,\n",
    "    head_order=\"hd\",\n",
    "    model_heads=[\n",
    "        'Commits', 'Commits', 'Commits',\n",
    "        'Library Use', 'Library Use', 'Library Use', 'Library Use',\n",
    "        'Library Entry', 'Library Entry', 'Library Entry', 'Library Entry'\n",
    "    ],\n",
    "    labels={\n",
    "        'log_Cuq': 'All Commits (log)',\n",
    "        'log_Cuq_mfiles': 'Multi-file (log)',\n",
    "        'log_Cuq_wimprt': 'Imports (log)',\n",
    "        'log_libQC_all': 'Combos (log)',\n",
    "        'log_libkQC_all': 'Combos (5k) (log)',\n",
    "        'log_libLQ_all': 'Combos (groups) (log)',\n",
    "        'log_libE_all': 'Individual Libs. (log)',\n",
    "        'log_libQC_new_u': 'Combos (log)',\n",
    "        'log_libkQC_new_u': 'Combos (5k) (log)',\n",
    "        'log_libLQ_new_u': 'Combos (groups) (log)',\n",
    "        'log_libE_new_u': 'Individual Libs. (log)',\n",
    "        'q': 'Quarter', 'IDu': 'User', 'L_AIavF': 'AI Use'\n",
    "    },\n",
    "    notes=\"Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient plot\n",
    "plot_coefficients(models, 'L_AIavF', 'main_regressions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-tex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX table output\n",
    "print(\n",
    "    pf.etable(\n",
    "        models,\n",
    "        head_order=\"hd\",\n",
    "        model_heads=[\n",
    "            'Commits', 'Commits', 'Commits',\n",
    "            'Library Use', 'Library Use', 'Library Use', 'Library Use',\n",
    "            'Library Entry', 'Library Entry', 'Library Entry', 'Library Entry'\n",
    "        ],\n",
    "        labels={\n",
    "            'log_Cuq': 'All Commits (log)',\n",
    "            'log_Cuq_mfiles': 'Multi-file (log)',\n",
    "            'log_Cuq_wimprt': 'Imports (log)',\n",
    "            'log_libQC_all': 'Combos (log)',\n",
    "            'log_libkQC_all': 'Combos (5k) (log)',\n",
    "            'log_libLQ_all': 'Combos (groups) (log)',\n",
    "            'log_libE_all': 'Individual Libs. (log)',\n",
    "            'log_libQC_new_u': 'Combos (log)',\n",
    "            'log_libkQC_new_u': 'Combos (5k) (log)',\n",
    "            'log_libLQ_new_u': 'Combos (groups) (log)',\n",
    "            'log_libE_new_u': 'Individual Libs. (log)',\n",
    "            'q': 'Quarter', 'IDu': 'User', 'L_AIavF': 'AI Use'\n",
    "        },\n",
    "        notes=\"Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001.\",\n",
    "        type=\"tex\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interactions",
   "metadata": {},
   "source": [
    "## Experience Interaction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interaction-regs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interaction models\n",
    "int_models, dvs = run_interaction_models(df)\n",
    "\n",
    "# Display table\n",
    "pf.etable(\n",
    "    int_models,\n",
    "    head_order=\"hd\",\n",
    "    model_heads=[\n",
    "        'Commits', 'Commits', 'Commits',\n",
    "        'Library Use', 'Library Use', 'Library Use', 'Library Use',\n",
    "        'Library Entry', 'Library Entry', 'Library Entry', 'Library Entry'\n",
    "    ],\n",
    "    labels={\n",
    "        'q': 'Quarter', 'IDu': 'User', 'L_AIavF': 'AI Use'\n",
    "    },\n",
    "    notes=\"Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interaction-tex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX output for interaction models\n",
    "print(\n",
    "    pf.etable(\n",
    "        int_models,\n",
    "        head_order=\"hd\",\n",
    "        model_heads=[\n",
    "            'Commits', 'Commits', 'Commits',\n",
    "            'Library Use', 'Library Use', 'Library Use', 'Library Use',\n",
    "            'Library Entry', 'Library Entry', 'Library Entry', 'Library Entry'\n",
    "        ],\n",
    "        labels={'q': 'Quarter', 'IDu': 'User', 'L_AIavF': 'AI Use'},\n",
    "        notes=\"Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001.\",\n",
    "        type=\"tex\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interaction-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interaction effects by experience group\n",
    "def plot_interaction_effects(models):\n",
    "    \"\"\"Plot AI effect separately for low/high experience groups.\"\"\"\n",
    "    labels = [\n",
    "        'All', 'Multi-file', 'Imports',\n",
    "        'Combos', 'Combos\\n(Top 5k)', 'Combos\\n(Groups)', 'Indiv.\\nLibs.',\n",
    "        'Combos', 'Combos\\n(Top 5k)', 'Combos\\n(Groups)', 'Indiv.\\nLibs.'\n",
    "    ]\n",
    "    \n",
    "    # Extract slopes by experience group\n",
    "    low_ests, low_los, low_his = [], [], []\n",
    "    high_ests, high_los, high_his = [], [], []\n",
    "    \n",
    "    for m in models:\n",
    "        sl = slopes(m, variables='L_AIavF', by='binned_experience', vcov=True).to_pandas()\n",
    "        sl['binned_experience'] = sl['binned_experience'].astype(int)\n",
    "        sl = sl.sort_values('binned_experience')\n",
    "        \n",
    "        low = sl[sl['binned_experience'] == 0].iloc[0]\n",
    "        high = sl[sl['binned_experience'] == 1].iloc[0]\n",
    "        \n",
    "        low_ests.append(low['estimate'])\n",
    "        low_los.append(low['conf_low'])\n",
    "        low_his.append(low['conf_high'])\n",
    "        high_ests.append(high['estimate'])\n",
    "        high_los.append(high['conf_low'])\n",
    "        high_his.append(high['conf_high'])\n",
    "    \n",
    "    low_ests = np.array(low_ests)\n",
    "    high_ests = np.array(high_ests)\n",
    "    low_yerr = np.vstack([low_ests - np.array(low_los), np.array(low_his) - low_ests])\n",
    "    high_yerr = np.vstack([high_ests - np.array(high_los), np.array(high_his) - high_ests])\n",
    "    \n",
    "    # Spacing\n",
    "    group_sizes = [3, 4, 4]\n",
    "    gap = 0.8\n",
    "    x_spaced = []\n",
    "    offset = 0.0\n",
    "    for gsize in group_sizes:\n",
    "        x_spaced.extend(offset + np.arange(gsize))\n",
    "        offset += gsize + gap\n",
    "    x_spaced = np.array(x_spaced)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12.0, 5.0), dpi=300)\n",
    "    width = 0.15\n",
    "    \n",
    "    ax.errorbar(x_spaced - width, low_ests, yerr=low_yerr, fmt=\"o\", capsize=3, \n",
    "                color='#1f77b4', label='Early-Career')\n",
    "    ax.errorbar(x_spaced + width, high_ests, yerr=high_yerr, fmt=\"o\", capsize=3,\n",
    "                color='#ff7f0e', label='Senior-Level')\n",
    "    \n",
    "    ax.axhline(0, lw=1, color=\"black\")\n",
    "    ax.set_xticks(x_spaced)\n",
    "    ax.set_xticklabels(labels, rotation=0, ha=\"center\", fontsize=13)\n",
    "    ax.set_xlim(x_spaced[0] - 0.6, x_spaced[-1] + 0.6)\n",
    "    ax.set_ylabel(\"Estimated marginal\\neffect of AI use\")\n",
    "    ax.legend(frameon=False, fontsize=13)\n",
    "    ax.tick_params(axis=\"y\", labelsize=13)\n",
    "    \n",
    "    # Group labels\n",
    "    sec = ax.secondary_xaxis(location=-0.17)\n",
    "    sec.spines['bottom'].set_visible(False)\n",
    "    sec.set_xticks(\n",
    "        [x_spaced[0:3].mean(), x_spaced[3:7].mean(), x_spaced[7:11].mean()],\n",
    "        labels=['Commits\\n(log)', 'Library Use\\n(log)', 'Library Entry\\n(log)'],\n",
    "        size=20\n",
    "    )\n",
    "    sec.tick_params('x', length=0)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'{OUTDIR}/interaction_regressions.pdf')\n",
    "    plt.show()\n",
    "\n",
    "plot_interaction_effects(int_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonlin",
   "metadata": {},
   "source": [
    "## Nonlinearity Check (Quintile Dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonlin-regs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run nonlinearity models with quintile dummies\n",
    "dvs = [\n",
    "    \"log_Cuq\", \"log_Cuq_mfiles\", \"log_Cuq_wimprt\",\n",
    "    \"log_libQC_all\", \"log_libkQC_all\", \"log_libLQ_all\", \"log_libE_all\",\n",
    "    \"log_libQC_new_u\", \"log_libkQC_new_u\", \"log_libLQ_new_u\", \"log_libE_new_u\"\n",
    "]\n",
    "\n",
    "nonlin_models = []\n",
    "for dv in dvs:\n",
    "    m = pf.feols(\n",
    "        f\"{dv} ~ C(binned_L_AIavF) | IDu + q\",\n",
    "        data=df,\n",
    "        vcov={'CRV1': 'IDu'}\n",
    "    )\n",
    "    nonlin_models.append(m)\n",
    "\n",
    "pf.etable(nonlin_models, coef_fmt=\"b \\n (se) \\n [p]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placebo",
   "metadata": {},
   "source": [
    "## Placebo Test (Pre-ChatGPT Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placebo-regs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run placebo regressions on pre-2022Q1 data\n",
    "placebo_models, _ = run_main_models(df_placebo)\n",
    "\n",
    "# Display table\n",
    "print(\n",
    "    pf.etable(\n",
    "        placebo_models,\n",
    "        head_order=\"hd\",\n",
    "        model_heads=[\n",
    "            'Commits', 'Commits', 'Commits',\n",
    "            'Library Use', 'Library Use', 'Library Use', 'Library Use',\n",
    "            'Library Entry', 'Library Entry', 'Library Entry', 'Library Entry'\n",
    "        ],\n",
    "        labels={'q': 'Quarter', 'IDu': 'User', 'L_AIavF': 'AI Use'},\n",
    "        notes=\"Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001.\",\n",
    "        type=\"tex\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placebo-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placebo coefficient plot\n",
    "plot_coefficients(\n",
    "    placebo_models, 'L_AIavF', 'placebo_regressions.pdf',\n",
    "    title='Placebo Regression (Pre-ChatGPT)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measurement",
   "metadata": {},
   "source": [
    "## Measurement Error: MA Window Extrapolation\n",
    "\n",
    "Test robustness of estimates across different moving average windows for AI exposure.\n",
    "Longer windows reduce measurement error; extrapolating to infinite window (1/w â†’ 0)\n",
    "gives the measurement-error-corrected estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ma-extrap",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_col(w):\n",
    "    \"\"\"Get MA column name for window w.\"\"\"\n",
    "    return f\"L_AIma{w}_iF\"\n",
    "\n",
    "\n",
    "def compute_ma_series(data, dv):\n",
    "    \"\"\"Compute estimates across MA windows for extrapolation.\"\"\"\n",
    "    xs, ests, los, his = [], [], [], []\n",
    "    for w in MA_WINDOWS:\n",
    "        reg = ma_col(w)\n",
    "        m = pf.feols(f\"{dv} ~ {reg} | IDu + q\", data=data, vcov={'CRV1': 'IDu'})\n",
    "        est, lo, hi = extract_ci(m, reg)\n",
    "        xs.append(1.0 / w)\n",
    "        ests.append(est)\n",
    "        los.append(lo)\n",
    "        his.append(hi)\n",
    "    return np.array(xs), np.array(ests), np.array(los), np.array(his)\n",
    "\n",
    "\n",
    "def plot_ma_extrapolation():\n",
    "    \"\"\"Create MA extrapolation plots for all DVs.\"\"\"\n",
    "    dvs = [\n",
    "        \"log_Cuq\", \"log_Cuq_mfiles\", \"log_Cuq_wimprt\",\n",
    "        \"log_libQC_all\", \"log_libkQC_all\", \"log_libLQ_all\", \"log_libE_all\",\n",
    "        \"log_libQC_new_u\", \"log_libkQC_new_u\", \"log_libLQ_new_u\", \"log_libE_new_u\"\n",
    "    ]\n",
    "    titles = [\n",
    "        'All Commits', 'Multi-file', 'Imports',\n",
    "        'Combos', 'Combos (Top 5k)', 'Combos (Groups)', 'Indiv. Libs.',\n",
    "        'Combos (New)', 'Combos 5k (New)', 'Combos Groups (New)', 'Indiv. Libs. (New)'\n",
    "    ]\n",
    "    \n",
    "    xticks = [1/32, 1/16, 1/8, 1/4]\n",
    "    xticklabels = [r\"$\\frac{1}{32}$\", r\"$\\frac{1}{16}$\", r\"$\\frac{1}{8}$\", r\"$\\frac{1}{4}$\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 3, figsize=(16, 12), dpi=300)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (dv, title) in enumerate(zip(dvs, titles)):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "        ax = axes[i]\n",
    "        xs, ests, los, his = compute_ma_series(df, dv)\n",
    "        \n",
    "        # Fit extrapolation line\n",
    "        coeffs = np.polyfit(xs, ests, deg=1)\n",
    "        a, b = coeffs[1], coeffs[0]\n",
    "        x_line = np.linspace(0, 0.3, 200)\n",
    "        y_line = a + b * x_line\n",
    "        \n",
    "        # Plot\n",
    "        yerr = np.vstack([ests - los, his - ests])\n",
    "        ax.errorbar(xs, ests, yerr=yerr, fmt=\"o\", capsize=3)\n",
    "        ax.plot(x_line, y_line, linewidth=1)\n",
    "        ax.axhline(0, linewidth=0.8, linestyle=\"--\", alpha=0.6)\n",
    "        \n",
    "        ax.set_xlim(0, 0.3)\n",
    "        ax.set_xticks(xticks)\n",
    "        ax.set_xticklabels(xticklabels)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "        ax.text(\n",
    "            0.93, 0.93, f\"Slope: {b:.3g}\",\n",
    "            transform=ax.transAxes, ha=\"right\", va=\"top\",\n",
    "            fontsize=10, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    axes[-1].axis('off')\n",
    "    \n",
    "    fig.supxlabel('1 / MA Window Size', fontsize=14)\n",
    "    fig.supylabel('Estimated Coefficient', fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'{OUTDIR}/ma_extrapolation.pdf')\n",
    "    plt.show()\n",
    "\n",
    "plot_ma_extrapolation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178e34a-23b9-4010-ba4c-efe4369f4eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a44440-0954-4869-a384-c79c19e989c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359674d9-f384-4024-8f68-d1fcddb7a285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
